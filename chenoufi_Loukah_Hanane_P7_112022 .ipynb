{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a5a447bb",
   "metadata": {},
   "source": [
    "Nous travaillons pour une société financière nommait \"Prêt à dépenser\" qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt. L’entreprise souhaite mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité qu’un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé. Il faudra développer un algorithme de classification en s'appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.).\n",
    "Les clients sont de plus en plus demandeurs de transparence vis-à-vis des décisions d’octroi de crédit.\n",
    "Prêt à dépenser décide donc de développer un dashboard interactif pour que les chargés de relation client puissent à la fois expliquer de façon la plus transparente possible les décisions d’octroi de crédit, mais également permettre à leurs clients de disposer de leurs informations personnelles et de les explorer facilement.\n",
    "\n",
    "Notre mission : - Construire un modèle de scoring qui donnera une prédiction sur la probabilité de faillite d'un client de façon automatique. - Construire un dashboard interactif à destination des gestionnaires de la relation client permettant d'interpréter les prédictions faites par le modèle, et d’améliorer la connaissance client des chargés de relation client.\n",
    "\n",
    "Spécifications du dashboard\n",
    "Michaël vous a fourni des spécifications pour le dashboard interactif. Celui-ci devra contenir au minimum les fonctionnalités suivantes :\n",
    "\n",
    "    Permettre de visualiser le score et l’interprétation de ce score pour chaque client de façon intelligible pour une personne non experte en data science.\n",
    "    Permettre de visualiser des informations descriptives relatives à un client (via un système de filtre).\n",
    "    Permettre de comparer les informations descriptives relatives à un client à l’ensemble des clients ou à un groupe de clients similaires.\n",
    "\n",
    "Sommaire :\n",
    "\n",
    "    Importation des librairies de bases et des dataset\n",
    "    Analyse exploratoire\n",
    "    Gestion des valeurs manquantes\n",
    "        Les types 'object'\n",
    "        Les types 'float64'\n",
    "    Gestion des outliers\n",
    "    Suppression des doublons"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9909370",
   "metadata": {},
   "source": [
    "A faire :\n",
    "\n",
    "afficher la matrice de confusion directement en sortie de pipeline ?\n",
    "\n",
    "tester un SVM avec kernel linéaire puis gaussien('rbf')/!\\ celui par défaut est le rbf (SVC.decision_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07baa3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74864bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import set_config\n",
    "import glob\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import time, pickle\n",
    "#Preprocessing, Upsampling, Model Selection, Model Evaluation\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, learning_curve, cross_validate\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "set_config(display='diagram')\n",
    "print('Imports terminés.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ac4c6",
   "metadata": {},
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba635fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\hlouk\\\\OpenClassroom\\\\P7')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aacc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CHECKLIST DATA EXPLORER :\")\n",
    "display(os.listdir('C:\\\\Users\\\\hlouk\\\\OpenClassroom\\\\P7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [\"n/a\", \"na\", \"--\",\"nan\",\"NaN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "dirpath = \"C:/Users/hlouk/OpenClassroom/P7/\"\n",
    "\n",
    "application_train = pd.read_csv(dirpath+\"application_train.csv\")\n",
    "application_test = pd.read_csv(dirpath+\"application_test.csv\")\n",
    "bureau = pd.read_csv(dirpath+\"bureau.csv\")\n",
    "bureau_balance = pd.read_csv(dirpath+\"bureau_balance.csv\")\n",
    "cash_balance = pd.read_csv(dirpath+\"POS_CASH_balance.csv\")\n",
    "card_balance = pd.read_csv(dirpath+\"credit_card_balance.csv\")\n",
    "prev_app = pd.read_csv(dirpath+\"previous_application.csv\")\n",
    "payments = pd.read_csv(dirpath+\"installments_payments.csv\")\n",
    "HomeCredit = pd.read_csv(dirpath+\"HomeCredit_columns_description.csv\",  na_values = missing_values, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919a831",
   "metadata": {},
   "source": [
    "Les données sont réparties en 9 fichiers.\n",
    "\n",
    "  1 fichier principal pour la partie \"training\" importé dans train_set (1 ligne / prêt)\n",
    "  1 fichier principal pour la partie \"test\" importé dans test_set (1 ligne / prêt)\n",
    "  1 fichier HomeCredit_columns_description propose le descriptif de chaque colonne dans chaque fichier\n",
    "  6 autres fichiers contenant des informations supplémentaires sur chaque prêt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f58b0",
   "metadata": {},
   "source": [
    "# Analyse et pré-traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af560b8",
   "metadata": {},
   "source": [
    "## Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf36151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "print('Training data shape: ', application_train.shape)\n",
    "application_train.describe()\n",
    "application_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "print('application_test shape: ', application_test.shape)\n",
    "application_test.describe()\n",
    "application_test.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9df91679",
   "metadata": {},
   "source": [
    "Le train_set est 6 fois plus imposant que le test_set et a une colone TARGET en plus ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791ed3c",
   "metadata": {},
   "source": [
    "## Autres Fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bureau\n",
    "print('Bureau data shape: ', bureau.shape)\n",
    "bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ade51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bureau balance\n",
    "print('Bureau balance data shape: ', bureau_balance.shape)\n",
    "bureau_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cash balance\n",
    "print('Cash balance data shape: ', cash_balance.shape)\n",
    "cash_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Card balance\n",
    "print('Card balance data shape: ', card_balance.shape)\n",
    "card_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8753cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous applications balance\n",
    "print('Previous applications data shape: ', prev_app.shape)\n",
    "prev_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payments balance\n",
    "print('Payments data shape: ', payments.shape)\n",
    "payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HomeCredit balance\n",
    "print('HomeCredit data shape: ', HomeCredit.shape)\n",
    "HomeCredit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d0de5e",
   "metadata": {},
   "source": [
    "# Analyse des données"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3de3db2f",
   "metadata": {},
   "source": [
    "Le tableau HomeCredit_columns_description propose le descriptif de chaque colonne dans chaque fichier. \n",
    "Commençons par créer une fonction qui permet de consulter ce descriptif pour une table donnée, ainsi qu'une fonction qui permet d'avoir un aperçu général d'une table donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_description=pd.read_csv(\"C:\\\\Users\\\\hlouk\\\\OpenClassroom\\\\P7\\\\HomeCredit_columns_description.csv\",encoding='latin1')\n",
    "\n",
    "def describe_sheet(sheet_name):\n",
    "    '''Display content of HomeCredit_columns_description for sheet_name table.'''\n",
    "    if 'application' in sheet_name:\n",
    "        sheet_name = dirpath + 'application_{train|test}'\n",
    "    description = columns_description[columns_description['Table'].str.contains(sheet_name)].iloc[:,2:]\n",
    "    description = description.set_index('Row')\n",
    "    return description\n",
    "        \n",
    "\n",
    "def overview(df_name):\n",
    "    '''Display information, result of describe, shape and head for given df_name.'''\n",
    "    df = globals()[df_name]\n",
    "    print('\\n\\n' + '#'*60)\n",
    "    print(f'Table {df_name}')\n",
    "    print('#'*60)\n",
    "    print(f'\\n\\nLa table {df_name} a {df.shape[0]:,.0f} lignes et {df.shape[1]:.0f} colonnes.'.replace(',', ' '))\n",
    "    print(f'\\n\\nDescription de la table :\\n')\n",
    "    display(describe_sheet(df_name))\n",
    "    print('\\n\\nPrincipales statistiques :\\n')\n",
    "    display(df.describe(include='all'))\n",
    "    print(f'\\n\\nPremières lignes :\\n')\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603b9cb",
   "metadata": {},
   "source": [
    "## Apercu des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_csv(dirpath + 'application_train.csv')\n",
    "\n",
    "overview('application_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bfa37b",
   "metadata": {},
   "source": [
    "## Les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_describe(folder):\n",
    "    '''Check the number of rows, columns, missing values and duplicates.\n",
    "       Count type of columns.\n",
    "       Memory indication'''\n",
    "\n",
    "    data_dict = {}\n",
    "    for file in folder:\n",
    "        if file == 'C:/Users/hlouk/OpenClassroom/P7\\HomeCredit_columns_description.csv':\n",
    "            data = pd.read_csv(file,  na_values = missing_values, encoding='latin1')\n",
    "        else:\n",
    "            data = pd.read_csv(file)\n",
    "        data_dict[file] = [data.shape[0], \n",
    "                           data.shape[1],\n",
    "                            round(data.isna().sum().sum()/data.size*100, 2),\n",
    "                            round(data.duplicated().sum().sum()/data.size*100, 2),\n",
    "                            data.select_dtypes(include=['object']).shape[1],\n",
    "                            data.select_dtypes(include=['float']).shape[1],\n",
    "                            data.select_dtypes(include=['int']).shape[1],\n",
    "                            data.select_dtypes(include=['bool']).shape[1],\n",
    "                            round(data.memory_usage().sum()/1024**2, 3)]\n",
    "\n",
    "        comparative_table = pd.DataFrame.from_dict(data = data_dict, \n",
    "                                                   columns = ['Rows', 'Columns', '%NaN', '%Duplicate', \n",
    "                                                              'object_dtype','float_dtype', 'int_dtype', \n",
    "                                                              'bool_dtype', 'MB_Memory'], \n",
    "                                                   orient='index')\n",
    "    print(\"SUMMARY FILES…\")\n",
    "    return(comparative_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b59ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data description  \n",
    "data_describe(folder = glob.glob('C:/Users/hlouk/OpenClassroom/P7/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79efe9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui calcule les valeurs manquantes par colone\n",
    "def missing_values_table(df):\n",
    "    # Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    "        \n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    # Print some summary information\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "           \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "           \" columns that have missing values.\")\n",
    "        \n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques des valeurs manquantes\n",
    "missing_values = missing_values_table(application_train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de chaque type de colonne\n",
    "# float64 et int64 pour des variables numériques\n",
    "# object pour des variables catégorielles\n",
    "application_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b115a95",
   "metadata": {},
   "source": [
    "## Les anomalies des valeurs numériques"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56b0590d",
   "metadata": {},
   "source": [
    "les distributions pour les variables numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ec569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_data(df):\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != 'object'] \n",
    "        \n",
    "    height = int(np.ceil(len(num_cols)/6))\n",
    "    fig_height = 3 * height\n",
    "    fig = plt.figure(figsize=(20,fig_height))\n",
    "    \n",
    "    for feat_idx, col in enumerate(num_cols):\n",
    "        ax = fig.add_subplot(height, 6, feat_idx+1)\n",
    "        ax.hist(df[col], bins=50)\n",
    "        ax.set_title(col)\n",
    "    fig.tight_layout(pad=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_data(df):\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != 'object'] \n",
    "    \n",
    "    height = int(np.ceil(len(num_cols)/6))\n",
    "    fig_height = 3 * height\n",
    "    fig = plt.figure(figsize=(20,fig_height))\n",
    "    \n",
    "    for feat_idx, col in enumerate(num_cols):\n",
    "        ax = fig.add_subplot(height, 6, feat_idx+1)\n",
    "        ax.boxplot(df[col])\n",
    "        ax.set_title(col)\n",
    "    fig.tight_layout(pad=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5faabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_hist_data(application_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6420342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_box_data(application_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(application_train['AMT_INCOME_TOTAL'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ca2600c",
   "metadata": {},
   "source": [
    "il y a des valeurs irréalistes de cette colonne\n",
    "Pour écarter les valeurs aberrantes, on utilisera le Z-score, c'est-à-dire la distance à la moyenne divisée par l'écart-type.\n",
    "Si Z-score > 3, la valeur peut être considérée comme un outlier puisqu'elle ne fait pas partie des 99,7% valeurs les plus proches de la moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db681628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(array, threshold=3):\n",
    "    '''Return an array of boolean, True for each value in the array where Z-score >threshold.'''\n",
    "    mean = array.mean()\n",
    "    std = array.std()\n",
    "    return abs((array-mean))/std > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_outliers = application_train[z_score(application_train['AMT_INCOME_TOTAL'])].shape[0]\n",
    "pc_outliers = nb_outliers / application_train.shape[0]\n",
    "print(f'Concernant la variable AMT_INCOME_TOTAL, on retrouve {nb_outliers} outliers \\\n",
    "qui représentent {pc_outliers:.2%} des cas.')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b73a64f",
   "metadata": {},
   "source": [
    "Examinons les 10 plus gros revenus de la liste des emprunteurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2\n",
    "application_train.sort_values(by='AMT_INCOME_TOTAL', ascending=False).head(10).style.format({'AMT_INCOME_TOTAL':'{:,.0f}'})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a7f8650",
   "metadata": {},
   "source": [
    "Puisque le model dois etre concu pour les gens aux revenues normaux, nous écarterons les données avec un Z-score supérieur à 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertissons-les temporairement en années écoulées (divison par -365) pour faciliter la vérification \n",
    "\n",
    "day_cols = [col for col in application_train.columns if \"DAYS_\" in col]\n",
    "(application_train[day_cols].describe().loc[['min', 'max']].transpose()/365).style.format({'min':'{:,.2f}', 'max':'{:,.2f}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(application_train[day_cols])[application_train['DAYS_EMPLOYED']>0].describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "286abff9",
   "metadata": {},
   "source": [
    "365243.0 est la valeur en commun entre plusieurs cases ce qui suggere une valeur aberrante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_count_pos = application_train['DAYS_EMPLOYED'][application_train['DAYS_EMPLOYED']>0].count()\n",
    "print(f\"Nombre de lignes avec des valeurs aberrantes pour DAYS_EMPLOYED : {days_count_pos} soit {days_count_pos/application_train.shape[0]:.2%} du total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche l'histogramme du nombre de jours employés\n",
    "fig = plt.figure(1, figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "application_train['DAYS_EMPLOYED'].hist()\n",
    "plt.xlabel('DAYS_EMPLOYED')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=30)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5dddbf52",
   "metadata": {},
   "source": [
    "Nombre de cas concernés est trop important pour supprimer purement et simplement les lignes correspondantes. Nous allons prendre le parti de transformer ces valeurs en la valeur réaliste la plus proche, soit 0. Aux yeux d'un banquier, ne pas avoir d'emploi est à peu près équivalent à démarrer dans un poste le jour même de la demande de prêt."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d2ed00e",
   "metadata": {},
   "source": [
    "Les nombres de la colonne DAYS_BIRTH sont négatifs car ils sont enregistrés par rapport à la demande de prêt en cours. Il est nécessaire de modifier cette variable pour obtenir des chiffres plus compréhensibles pour l'analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âge \n",
    "\n",
    "for col  in day_cols:\n",
    "    idx = application_train[application_train[col]<application_train['DAYS_BIRTH']].index\n",
    "    idx_exist = len(idx)\n",
    "    if idx_exist:\n",
    "        print(col, 'présente des valeurs aberrantes aux lignes :', list(idx))\n",
    "        for i in idx:\n",
    "            print(application_train.loc[i,[col, 'DAYS_BIRTH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(application_train['DAYS_BIRTH'] / -365).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16482b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.histplot((application_train['DAYS_BIRTH'] / -365), bins = 30).set_title('Age of client')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train[application_train['DAYS_EMPLOYED']>0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e864ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram', figsize=(20,5));\n",
    "plt.xlabel('Days Employment')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b393be8b",
   "metadata": {},
   "source": [
    " ces données ne sont pas \"normales\" au sens où le Max. représente 1000 années (365243/365j). Est-ce un individu isolé? Plusieurs individus de l'échantillon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.0f values with 365243 days employed for training data\" % \n",
    "      len(application_train[application_train['DAYS_EMPLOYED'] == 365243]))\n",
    "print(\"%0.0f Total values from days employed for training data\" % application_train.shape[0])\n",
    "print(\"***********************\")\n",
    "print(\"%0.0f values with 365243 days employed for testing data\" % \n",
    "      len(application_test[application_test['DAYS_EMPLOYED'] == 365243]))\n",
    "print(\"%0.0f Total values from days employed for testing data\" % application_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an outliers flag column\n",
    "application_train['DAYS_EMPLOYED_OUTLIERS'] = application_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "application_test['DAYS_EMPLOYED_OUTLIERS'] = application_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "#Replace outliers values with nan\n",
    "application_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "application_test['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train['DAYS_EMPLOYED'].plot.hist(title ='Days Employment with preprocessing outliers', figsize=(20,5))\n",
    "plt.xlabel('Days Employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in day_cols:\n",
    "    application_train.loc[application_train[col]< application_train['DAYS_BIRTH'], col] = application_train['DAYS_BIRTH']\n",
    "    application_train.loc[application_train[col]>0, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e93f8",
   "metadata": {},
   "source": [
    "### Variables qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [col for col in application_train.columns if application_train[col].dtype == 'object']:\n",
    "    print(col,\":\", list(application_train[col].unique()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6e227c3",
   "metadata": {},
   "source": [
    "Il ne nous paraît pas possible dans ce dataset de procéder à une imputation, chaque dossier étant unique. Mais les modèles n'acceptant pas la valeur NaN, si une donnée n'est pas connue, elle sera considérée comme nulle ou vide (selon sa nature) lors de la normalisation.\n",
    "\n",
    "On complète clean_values() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e02f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_values(df):\n",
    "    print('Nettoyage des lignes...')\n",
    "    \n",
    "    old_length = df.shape[0]\n",
    "    result = df.copy()\n",
    "    num_cols = [col for col in result.columns if result[col].dtype!='object']\n",
    "    cat_cols = [col for col in result.columns if col not in num_cols]\n",
    "    \n",
    "    high_z_score = result[num_cols].apply(z_score, axis=0, args=[80])\n",
    "    result.drop(high_z_score[high_z_score.any(axis=1)].index, inplace=True)\n",
    "    \n",
    "    days_cols = [col for col in result.columns if \"DAYS_\" in col]\n",
    "    for col in day_cols:\n",
    "        result.loc[result[col]< result['DAYS_BIRTH'], col] = result['DAYS_BIRTH']\n",
    "        result.loc[result[col]>0, col] = 0\n",
    "        \n",
    "    result[num_cols]=result[num_cols].fillna(0)\n",
    "    result[cat_cols]=result[cat_cols].fillna('Not specified')\n",
    "    \n",
    "    new_length = result.shape[0]\n",
    "    deleted_rows = old_length - new_length\n",
    "    print(f'{deleted_rows} lignes ont été supprimées soit {deleted_rows/old_length:.2%} du total.')\n",
    "  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1bd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = clean_values(application_train)\n",
    "application_test = clean_values(application_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d2fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stat(data, feature, title) : \n",
    "    \n",
    "    ax, fig = plt.subplots(figsize=(20,8)) \n",
    "    ax = sns.countplot(y=feature, data=data, order=data[feature].value_counts(ascending=False).index)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    for p in ax.patches:\n",
    "                percentage = '{:.1f}%'.format(100 * p.get_width()/len(data[feature]))\n",
    "                x = p.get_x() + p.get_width()\n",
    "                y = p.get_y() + p.get_height()/2\n",
    "                ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')\n",
    "\n",
    "def plot_percent_target1(data, feature, title) : \n",
    "    \n",
    "    cat_perc = data[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\n",
    "    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n",
    "    \n",
    "    ax, fig = plt.subplots(figsize=(20,8)) \n",
    "    ax = sns.barplot(y=feature, x='TARGET', data=cat_perc)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Percent of target with value 1\")\n",
    "\n",
    "    for p in ax.patches:\n",
    "                percentage = '{:.1f}%'.format(100 * p.get_width())\n",
    "                x = p.get_x() + p.get_width()\n",
    "                y = p.get_y() + p.get_height()/2\n",
    "                ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de752022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(20,8)) \n",
    "ax = sns.countplot(y='TARGET', data=application_train)\n",
    "ax.set_title(\"Distribution du TARGET\")\n",
    "\n",
    "for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_width()/len(application_train.TARGET))\n",
    "        x = p.get_x() + p.get_width()\n",
    "        y = p.get_y() + p.get_height()/2\n",
    "        ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da8f104a",
   "metadata": {},
   "source": [
    "Loan types - Distribution du type de prêts contractés + comparatif avec le pourcentage des prêts avec la valeur TARGET 1(prêt non retourné).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e518b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NAME_CONTRACT_TYPE\n",
    "plot_stat(application_train, 'NAME_CONTRACT_TYPE',\"Type of contract\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'NAME_CONTRACT_TYPE',\"Type of contract %Target1\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82a54348",
   "metadata": {},
   "source": [
    "Les prêts renouvelables ne représentent qu'une petite fraction (10%) du nombre total de prêts; dans le même temps, un plus grand nombre de crédits renouvelables, par rapport à leur fréquence, ne sont pas remboursés.\n",
    "\n",
    "Client gender - Distribution H/F clients, mais aussi le pourcentage des prêts (par sexe du client) avec la valeur TARGET 1 (prêt non retourné).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5bb63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CODE_GENDER\n",
    "plot_stat(application_train, 'CODE_GENDER',\"GENDER Distribution\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'CODE_GENDER',\"GENDER Distribution %Target1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a820283d",
   "metadata": {},
   "source": [
    "Le nombre de clients féminins est presque le double du nombre de clients masculins. En ce qui concerne le pourcentage de crédits en souffrance, les hommes ont plus de chances de ne pas rembourser leurs prêts (10%), comparativement aux femmes (7%).\n",
    "\n",
    "Flag own car - Distribution d'un impact possible entre les clients propriétaire d'un véhicule et ceux qui ne le sont pas…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAG_OWN_CAR\n",
    "plot_stat(application_train, 'FLAG_OWN_CAR',\"Car owner\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'FLAG_OWN_CAR',\"Car owner %Target1\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c30a8e6",
   "metadata": {},
   "source": [
    "Les deux catégories (propriétaire ou non) ont des taux de non-remboursement d'environ 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83617114",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NAME_FAMILY_STATUS\n",
    "plot_stat(application_train, 'NAME_FAMILY_STATUS',\"Family status\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'NAME_FAMILY_STATUS',\"Family status %Target1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32ac8cc8",
   "metadata": {},
   "source": [
    "La plupart des clients sont mariés, suivis des célibataires / non mariés et des mariages civils.\n",
    "\n",
    "En termes de pourcentage de non-remboursement du prêt, le mariage civil a le pourcentage le plus élevé de non-remboursement (10%), la veuve étant le plus bas (à l'exception de l'inconnu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c78007",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NAME_INCOME_TYPE\n",
    "plot_stat(application_train, 'NAME_INCOME_TYPE',\"Income type of client\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'NAME_INCOME_TYPE',\"Income type of client %Target1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84c0f7a5",
   "metadata": {},
   "source": [
    "La plupart des demandeurs de prêts sont des revenus du travail, suivis par un associé commercial, un retraité et un fonctionnaire.\n",
    "\n",
    "Les demandeurs avec le type de revenu Congé de maternité ont un ratio de près de 40% de prêts non remboursés, suivis des chômeurs (37%). Les autres types de revenus sont inférieurs à la moyenne de 10% pour ne pas rembourser les prêts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e96a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OCCUPATION_TYPE\n",
    "plot_stat(application_train, 'OCCUPATION_TYPE',\"Ocupation of client\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'OCCUPATION_TYPE',\"Ocupation of client %Target1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c59c25b4",
   "metadata": {},
   "source": [
    "La plupart des prêts sont contractés par des ouvriers, suivis par les vendeurs/commerciaux. Le personnel informatique prend le montant de prêts le plus bas.\n",
    "\n",
    "La catégorie avec le pourcentage le plus élevé de prêts non remboursés est celle des ouvriers peu qualifiés (plus de 17%), suivis des chauffeurs et des serveurs / barmen, du personnel de sécurité, des ouvriers et du personnel de cuisine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddf059",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NAME_EDUCATION_TYPE\n",
    "plot_stat(application_train, 'NAME_EDUCATION_TYPE',\"Education type of the client\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'NAME_EDUCATION_TYPE',\"Education type of the client %Target1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fb40b85",
   "metadata": {},
   "source": [
    "La majorité des clients ont une éducation dans l'éducation secondaire, suivis des clients avec une éducation supérieure. Un très petit nombre d'emprunteur possède un diplôme universitaire.\n",
    "\n",
    "La catégorie du premier cycle du secondaire, bien que rare, a le taux le plus élevé de non-remboursement du prêt (11%). Les personnes ayant un diplôme universitaire ont un taux de non-remboursement inférieur à 2%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdef4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAME_HOUSING_TYPE\n",
    "plot_stat(application_train, 'NAME_HOUSING_TYPE',\"Type of the housing of client\")\n",
    "print(\"                                   -------------------------------------------------------\")\n",
    "plot_percent_target1(application_train, 'NAME_HOUSING_TYPE',\"Type of the housing of client %Target1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a0d0466",
   "metadata": {},
   "source": [
    "Plus de 250 000 demandeurs de crédits vivent en maison ou appartement. Les catégories suivantes, faible pourcentage, représentent une population moins \"indépendante\" (vivre chez ses parents, etc…).\n",
    "\n",
    "Dans ces catégories, les loueurs d'appartements (non propriétaires de leur résidence principale), ainsi que ceux qui vivent chez leurs parents, ont un taux de non-remboursement supérieur à 10%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c4206",
   "metadata": {},
   "source": [
    "# Method #1: Modelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOME CREDIT DEFAULT RISK COMPETITION\n",
    "# Most features are created by applying min, max, mean, sum and var functions to grouped tables. \n",
    "# Little feature selection is done and overfitting might be a problem since many features are related.\n",
    "# The following key ideas were used:\n",
    "# - Divide or subtract important features to get rates (like annuity and income)\n",
    "# - In Bureau Data: create specific features for Active credits and Closed credits\n",
    "# - In Previous Applications: create specific features for Approved and Refused applications\n",
    "# - Modularity: one function for each table (except bureau_balance and application_test)\n",
    "# - One-hot encoding for categorical features\n",
    "# All tables are joined with the application DF using the SK_ID_CURR key (except bureau_balance).\n",
    "# You can use LightGBM with KFold or Stratified KFold.\n",
    "\n",
    "# Update 16/06/2018:\n",
    "# - Added Payment Rate feature\n",
    "# - Removed index from features\n",
    "# - Use standard KFold CV (not stratified)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import json ,lightgbm\n",
    "import re\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('../P7/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('../P7/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    '''for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])'''\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Some simple new features (percentages)\n",
    "    \n",
    "\n",
    "    #INCOME_CREDIT_PERC: Pourcentage du montant du crédit par rapport au revenu d'un client\n",
    "    #ANNUITY_INCOME_PERC: Pourcentage de la rente de prêt par rapport au revenu d'un client\n",
    "    #DAYS_EMPLOYED_PERC: Pourcentage des jours employés par rapport à l'âge du client\n",
    "       \n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('../P7/bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('../P7/bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg\n",
    "\n",
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('../P7/previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('../P7/POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('../P7/installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('../P7/credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "    test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "        \n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1 )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651378c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')\n",
    "\n",
    "\n",
    "def main(debug = False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False, debug= debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baaf7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf21d9",
   "metadata": {},
   "source": [
    "# Method #2: Modelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a155af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import json ,lightgbm\n",
    "import re\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    #df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('../P7/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('../P7/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    '''for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])'''\n",
    "    # Categorical features with One-Hot encode\n",
    "    #df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    #df['DAYS_BIRTH'] = df[df['DAYS_BIRTH']/ -365]\n",
    "    #(application_train['DAYS_BIRTH'] / -365).describe()\n",
    "    \n",
    "    # Some simple new features (percentages)\n",
    "    \n",
    "\n",
    "    #INCOME_CREDIT_PERC: Pourcentage du montant du crédit par rapport au revenu d'un client\n",
    "    #ANNUITY_INCOME_PERC: Pourcentage de la rente de prêt par rapport au revenu d'un client\n",
    "    #DAYS_EMPLOYED_PERC: Pourcentage des jours employés par rapport à l'âge du client\n",
    "       \n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('../P7/bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('../P7/bureau_balance.csv', nrows = num_rows)\n",
    "    \n",
    "    \n",
    "    #Total number of previous credits taken by each customer\n",
    "    previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(\n",
    "                                       columns = {'SK_ID_BUREAU': 'PREVIOUS_LOANS_COUNT'})\n",
    "\n",
    "#Monthly average balances of previous credits in Credit Bureau.\n",
    "    bureau_bal_mean = bb.groupby('SK_ID_BUREAU', as_index=False).mean().rename(columns = \n",
    "                                        {'MONTHS_BALANCE': 'MONTHS_BALANCE_MEAN'})\n",
    "    bureau_full = bureau.merge(bureau_bal_mean, on='SK_ID_BUREAU', how='left')\n",
    "\n",
    "    bureau_mean = bureau_full.groupby('SK_ID_CURR', as_index=False).mean().add_prefix('PREV_BUR_MEAN_')\n",
    "    bureau_mean = bureau_mean.rename(columns = {'PREV_BUR_MEAN_SK_ID_CURR' : 'SK_ID_CURR'})\n",
    "\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    return previous_loan_counts, bureau_mean\n",
    "\n",
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('../P7/previous_application.csv', nrows = num_rows)\n",
    "    #prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    \n",
    "     #Number of previous applications of the clients to Home Credit\n",
    "    previous_application_counts = prev.groupby('SK_ID_CURR', \n",
    "                                                           as_index=False)['SK_ID_PREV'].count().rename(\n",
    "                                                           columns = {'SK_ID_PREV': 'PREVIOUS_APPLICATION_COUNT'})\n",
    "    \n",
    "    # Previous applications numeric features\n",
    "    return previous_application_counts, prev\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('../P7/POS_CASH_balance.csv', nrows = num_rows)\n",
    "    \n",
    "    POS_mean = pos.groupby('SK_ID_PREV', as_index=False).mean().add_prefix('POS_MEAN_')\n",
    "    POS_mean.rename(columns = {'POS_MEAN_SK_ID_PREV' : 'SK_ID_PREV'}, inplace=True)\n",
    "\n",
    "    return POS_mean\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('../P7/installments_payments.csv', nrows = num_rows)\n",
    "    #ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    install_pay_mean = ins.groupby('SK_ID_PREV', as_index=False).mean().add_prefix('INSTALL_MEAN_')\n",
    "    install_pay_mean.rename(columns = {'INSTALL_MEAN_SK_ID_PREV' : 'SK_ID_PREV'}, inplace=True)\n",
    "\n",
    "    return install_pay_mean\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('../P7/credit_card_balance.csv', nrows = num_rows)\n",
    "    #cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    #cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    credit_card_balance_mean = cc.groupby('SK_ID_PREV', as_index=False).mean().add_prefix('CARD_MEAN_')\n",
    "    credit_card_balance_mean.rename(columns = {'CARD_MEAN_SK_ID_PREV' : 'SK_ID_PREV'}, inplace=True)\n",
    "\n",
    "    return credit_card_balance_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea54dd",
   "metadata": {},
   "source": [
    "## LGBM- Pre tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40000 #if debug else None\n",
    "df = application_train_test(num_rows)\n",
    "\n",
    "with timer(\"Process bureau and bureau_balance\"):\n",
    "        previous_loan_counts, bureau_mean = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.merge(previous_loan_counts, on='SK_ID_CURR', how='left')\n",
    "        df = df.merge(bureau_mean, on='SK_ID_CURR', how='left')\n",
    "        del previous_loan_counts, bureau_mean\n",
    "        \n",
    "with timer(\"Process previous_applications\"):\n",
    "        prev, prev2 = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df.merge(prev, on='SK_ID_CURR', how='left')\n",
    "        del prev\n",
    "        \n",
    "with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        prev2 = prev2.merge(pos, on='SK_ID_PREV', how='left')\n",
    "        del pos\n",
    "        \n",
    "with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        #df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        prev2 = prev2.merge(ins, on='SK_ID_PREV', how='left')\n",
    "        del ins\n",
    "        \n",
    "with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        prev2= prev2.merge(cc, on='SK_ID_PREV', how='left')\n",
    "        del cc\n",
    "        \n",
    "'''    with timer(\"Run LightGBM with kfold\"):\n",
    "        feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False, debug= debug)\n",
    "'''\n",
    "prev_appl_mean = prev2.groupby('SK_ID_CURR', as_index=False).mean().add_prefix('PREV_APPL_MEAN_')\n",
    "prev_appl_mean.rename(columns = {'PREV_APPL_MEAN_SK_ID_CURR' : 'SK_ID_CURR'}, inplace=True)\n",
    "prev_appl_mean = prev_appl_mean.drop('PREV_APPL_MEAN_SK_ID_PREV', axis=1)\n",
    "\n",
    "\n",
    "#Last merge with our data sample\n",
    "df= df.merge(prev_appl_mean, on='SK_ID_CURR', how='left')\n",
    "\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import time, pickle\n",
    "from zipfile import ZipFile\n",
    "#Preprocessing, Upsampling, Model Selection, Model Evaluation\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from contextlib import contextmanager\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, learning_curve, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import json ,lightgbm\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e33be",
   "metadata": {},
   "source": [
    "### Remove N/A columns and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global view of the missing values (black)\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df.notna(), cbar=False)\n",
    "#show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c990f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_check(data):\n",
    "    '''Check Missing Values'''\n",
    "    total = data.isnull().sum()\n",
    "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "    percent_2 = (np.round(percent_1, 2))\n",
    "    missing_data = pd.concat([total, percent_2], \n",
    "                             axis=1, keys=['Total', '%']).sort_values('%', ascending=False)\n",
    "    missing_data = missing_data.reset_index()\n",
    "    missing_data.columns = ['Col_Name','Total', '%']\n",
    "    return missing_data\n",
    "\n",
    "print('TOP 20 Missing values from Training dataset')\n",
    "nan_check(df)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nb of columns in the training sample: \" + str(len(nan_check(df))))\n",
    "\n",
    "print(\"Nb of columns in the training sample with missing values: \" + \n",
    "      str(len(nan_check(df)[nan_check(df)['Total']!=0])))\n",
    "\n",
    "print(\"Nb of columns in the training sample with 55% missing values: \" + \n",
    "      str(len(nan_check(df)[nan_check(df)['%']>=55])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepCol = nan_check(df)[nan_check(df)['%']<=55]\n",
    "column_keep = list(keepCol['Col_Name'].values)\n",
    "\n",
    "#Nouvelle liste avec les colonnes conservées\n",
    "df = df[column_keep]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95295c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global view of the missing values (black)\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df.notna(), cbar=False)\n",
    "#show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43702a04",
   "metadata": {},
   "source": [
    "### Encode Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, cat_cols = one_hot_encoder(df, nan_as_category= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b95b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.shape)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.drop('FLAG_DOCUMENT_12', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a34206",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Display correlations with features engineering\n",
    "print('Most Positive Correlations:\\n', df2.corr()['TARGET'].sort_values().tail(15))\n",
    "print(\"--------------------------\")\n",
    "print('Most Negative Correlations:\\n', df2.corr()['TARGET'].sort_values().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b302fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df2[df2['SK_ID_CURR'].isin(application_train.SK_ID_CURR)]\n",
    "data_test = df2[df2['SK_ID_CURR'].isin(application_test.SK_ID_CURR)]\n",
    "\n",
    "data_test = data_test.drop('TARGET', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90294c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.set_index('SK_ID_CURR', inplace=True)\n",
    "data_test.set_index('SK_ID_CURR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97583bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features shape with categorical columns: ', data_train.shape)\n",
    "print('Testing Features shape with categorical columns: ', data_test.shape)\n",
    "print('Full data Features shape with categorical columns: ', df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88dfc5",
   "metadata": {},
   "source": [
    "### Missing data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values in train data: ', sum(data_train.isnull().sum()))\n",
    "print('Missing values in test data: ', sum(data_test.isnull().sum()))\n",
    "print('Missing values in full data: ', sum(df2.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "data_train.iloc[:,:] = imputer.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244edd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "data_test.iloc[:,:] = imputer.fit_transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Imputation step\n",
    "print(sum(data_train.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e10950",
   "metadata": {},
   "source": [
    "## Modeling Primaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = data_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET.to_csv('TARGET.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in data_train.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "data_train = data_train[feats]\n",
    "data_test = data_test[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955442e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features shape with categorical columns: ', data_train.shape)\n",
    "print('Testing Features shape with categorical columns: ', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc082e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nouvelle liste avec les colonnes conservées\n",
    "df_orig = df[categorical_columns]\n",
    "df_orig['SK_ID_CURR'] = df['SK_ID_CURR']\n",
    "df_orig = df_orig[df_orig['SK_ID_CURR'].isin(application_train.SK_ID_CURR)]\n",
    "\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb49ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_risk = data_train.merge(df_orig, on='SK_ID_CURR', how='left')\n",
    "default_risk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65186d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "compression_opts = dict(method='zip', archive_name='default_risk.csv')\n",
    "default_risk.to_csv('default_risk.zip', index=True, compression=compression_opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4086b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data =None\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train, TARGET.values, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eca25e",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8511757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Fit scaler to our training data\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(data_train)\n",
    "scaled_train = scaler.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa166eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(data_test)\n",
    "scaled_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcdbd1",
   "metadata": {},
   "source": [
    "## Confustion Matrix and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca65ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_matrix_roc_auc(model, y_true, y_pred, y_pred_proba, feature_importances):\n",
    "    '''This function will make a pretty plot of \n",
    "  an sklearn Confusion Matrix using a Seaborn heatmap visualization + ROC Curve.'''\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "  \n",
    "    plt.subplot(221)\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "  \n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    fpr,tpr,_ = roc_curve(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, color='orange', linewidth=5, label='AUC = %0.4f' %roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "\n",
    "    if feature_importances and X_data is not None : \n",
    "        plt.subplot(212)\n",
    "        indices = np.argsort(model.feature_importances_)[::-1]\n",
    "    \n",
    "    features = []\n",
    "    if X_data is not None:\n",
    "        for i in range(20):\n",
    "            features.append(X_data.columns[indices[i]]) #After RFECV selection > X_data created\n",
    "\n",
    "        sns.barplot(x=features, y=model.feature_importances_[indices[range(20)]], color=(\"orange\"))\n",
    "        plt.xlabel('Features importance')\n",
    "        plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064055fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictive Model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "models = [\n",
    "          LGBMClassifier(device='gpu')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22727a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model, X_train, X_test, y_train, y_test):\n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    model.fit(X_train, y_train)\n",
    "    output = {\n",
    "      'AUC': roc_auc_score(y_test, model.predict_proba(X_test)[:,1]),\n",
    "      'Accuracy': accuracy_score(y_test, model.predict(X_test)),\n",
    "      'Precision': precision_score(y_test, model.predict(X_test)),\n",
    "      'Recall': recall_score(y_test, model.predict(X_test)),\n",
    "      'F1': f1_score(y_test, model.predict(X_test)),\n",
    "      'F2': fbeta_score(y_test, model.predict(X_test), beta=2, average='binary')\n",
    "      }\n",
    "          \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name = []\n",
    "auc = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "time_ = []\n",
    "\n",
    "for model in models:\n",
    "    start = time.time()    \n",
    "    results = train_models(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    name.append(type(model).__name__)\n",
    "    auc.append(results['AUC'])\n",
    "    accuracy.append(results['Accuracy'])\n",
    "    precision.append(results['Precision'])\n",
    "    recall.append(results['Recall'])\n",
    "    f1.append(results['F1'])\n",
    "    f2.append(results['F2'])\n",
    "    time_.append(time.time()-start)\n",
    "\n",
    "#Initialise data of lists\n",
    "base_models = pd.DataFrame(data=[name, auc, accuracy, precision, recall, f1, f2, time_]).T\n",
    "base_models.columns = ['Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'Time']\n",
    "base_models.sort_values('AUC', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49779174",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "cf_matrix_roc_auc(model, y_test, model.predict(X_test), model.predict_proba(X_test)[:,1], feature_importances=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d4540",
   "metadata": {},
   "source": [
    "##  Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de66972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE with Imbalance Data using imblearn module\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"Label 1, Before using SMOTE: {} \".format(sum(y_train==1)))\n",
    "print(\"Label 0, Before using SMOTE: {} \".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 1, After using SMOTE: {}\".format(sum(y_train_res==1)))\n",
    "print(\"Label 0, After using SMOTE: {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce904128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name = []\n",
    "auc = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "time_ = []\n",
    "\n",
    "for model in models:\n",
    "    start = time.time()    \n",
    "    results = train_models(model, X_train_res, X_test, y_train_res, y_test)\n",
    "\n",
    "    name.append(type(model).__name__)\n",
    "    auc.append(results['AUC'])\n",
    "    accuracy.append(results['Accuracy'])\n",
    "    precision.append(results['Precision'])\n",
    "    recall.append(results['Recall'])\n",
    "    f1.append(results['F1'])\n",
    "    f2.append(results['F2'])\n",
    "    time_.append(time.time()-start)\n",
    "\n",
    "#Initialise data of lists\n",
    "base_models_sm = pd.DataFrame(data=[name, auc, accuracy, precision, recall, f1, f2, time_]).T\n",
    "base_models_sm.columns = ['Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1', 'F2','Time']\n",
    "base_models_sm.sort_values('AUC', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18337705",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    cf_matrix_roc_auc(model, y_test, model.predict(X_test), model.predict_proba(X_test)[:,1], feature_importances=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a2555",
   "metadata": {},
   "source": [
    "## Feature Selection "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a792c24",
   "metadata": {},
   "source": [
    "LGBMClassifier permet d'obtenir les meilleurs performances AUC score / Time. \n",
    "L'ensembles de données contiennent 309 features total et 219 dans notre echantillon, dont beaucoup peuvent ne pas contenir d'informations utiles. \n",
    "RFECV avec Scikit-learn appliquera une validation croisée pour trouver l'ensemble des features optimal qui maximisera nos performances. \n",
    "Le but est donc d'optimiser la métrique AUC tout en éliminant les features les moins importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5ea84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "rfecv = RFECV(estimator=LGBMClassifier(objective='binary'), \n",
    "              step=5, \n",
    "              cv=StratifiedKFold(5), \n",
    "              scoring='roc_auc', \n",
    "              verbose=2,\n",
    "              n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print('Time Elapsed: {}'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "print(\"Selected Features: %s\" % rfecv.support_[:20])\n",
    "print(\"Feature Ranking : %s\" % rfecv.ranking_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = pd.DataFrame({'Features': data_train.columns})\n",
    "ranking['RANK'] = np.asarray(rfecv.ranking_)\n",
    "ranking.sort_values('RANK', inplace=True)\n",
    "\n",
    "features_selection = ranking[ranking.RANK == 1]['Features'].to_list()\n",
    "print(len(features_selection))\n",
    "print(features_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot number of features vs CV scores\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "step=5\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.xlabel('Number of features tested (x%d)' % step)\n",
    "plt.ylabel('Cross-validation score (roc_auc)')\n",
    "#show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d805efdb",
   "metadata": {},
   "source": [
    "RFECV explique l'importance des features sélectionnées en fonction de l'évolution du score AUC, comme l'atteste également le plot ci-dessus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=ranking.copy()\n",
    "test['Row'] =test.reset_index().index\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('features_description.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data_train.loc[:, data_train.columns[rfecv.get_support()]]\n",
    "print(X_data.shape)\n",
    "X_test = data_test.loc[:, data_test.columns[rfecv.get_support()]]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('X_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge operation with TARGET before save this reduced sample\n",
    "X_data = X_data.merge(TARGET, left_index=True, right_index=True)\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e114f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "compression_opts = dict(method='zip', archive_name='X_data.csv')\n",
    "X_data.to_csv('X_data.zip', index=True, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data with rfecv \n",
    "X_train_selected = rfecv.transform(X_train)\n",
    "X_test_selected = rfecv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "rf_basic = RandomForestClassifier(n_estimators=1000)\n",
    "#rf_basic.max_depth = 150\n",
    "# Training the basic Decision Tree model with training set \n",
    "rf_basic.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predicting the output of the test cases using the algorithm created above\n",
    "y_pre = rf_basic.predict(X_test_selected)\n",
    "\n",
    "# Validating the algorithm using various Performance metrics\n",
    "\n",
    "a1 = accuracy_score(y_test,y_pre)\n",
    "f1 = f1_score(y_test, y_pre, average=\"macro\")\n",
    "f2 = fbeta_score(y_test, y_pre, beta=2, average=\"binary\")\n",
    "p1 = precision_score(y_test, y_pre, average=\"macro\")\n",
    "r1 = recall_score(y_test, y_pre, average=\"macro\")\n",
    "print(\"accuracy score : \",a1)\n",
    "print(\"f1 score : \",f1)\n",
    "print(\"f2 score : \",f2)\n",
    "print(\"precision score : \",p1)\n",
    "print(\"recall score : \",r1)\n",
    "\n",
    "# Computing Confusion matrix for the above algorithm\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pre)\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed36c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, rf_basic.predict_proba(X_test_selected)[:,1])\n",
    "cf_matrix_roc_auc(rf_basic, y_test, rf_basic.predict(X_test_selected), rf_basic.predict_proba(X_test_selected)[:,1], feature_importances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a69f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use reduced features with decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "\n",
    "dectree_basic = DecisionTreeClassifier()\n",
    "dectree_basic.max_depth = 150\n",
    "# Training the basic Decision Tree model with training set \n",
    "dectree_basic.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predicting the output of the test cases using the algorithm created above\n",
    "y_pre = dectree_basic.predict(X_test_selected)\n",
    "\n",
    "# Validating the algorithm using various Performance metrics\n",
    "\n",
    "a1 = accuracy_score(y_test,y_pre)\n",
    "f1 = f1_score(y_test, y_pre, average=\"macro\")\n",
    "f2 = fbeta_score(y_test, y_pre, beta=2, average=\"binary\")\n",
    "p1 = precision_score(y_test, y_pre, average=\"macro\")\n",
    "r1 = recall_score(y_test, y_pre, average=\"macro\")\n",
    "print(\"accuracy score : \",a1)\n",
    "print(\"f1 score : \",f1)\n",
    "print(\"f2 score : \",f2)\n",
    "print(\"precision score : \",p1)\n",
    "print(\"recall score : \",r1)\n",
    "\n",
    "# Computing Confusion matrix for the above algorithm\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pre)\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcda03a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, dectree_basic.predict_proba(X_test_selected)[:,1])\n",
    "cf_matrix_roc_auc(dectree_basic, y_test, dectree_basic.predict(X_test_selected), dectree_basic.predict_proba(X_test_selected)[:,1], feature_importances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28307f9f",
   "metadata": {},
   "source": [
    "Using Reduced features with lgbm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71830d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model, X_train_selected, X_test_selected, y_train, y_test):\n",
    "\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    output = {\n",
    "      'AUC': roc_auc_score(y_test, model.predict_proba(X_test_selected)[:,1]),\n",
    "      'Accuracy': accuracy_score(y_test, model.predict(X_test_selected)),\n",
    "      'Precision': precision_score(y_test, model.predict(X_test_selected)),\n",
    "      'Recall': recall_score(y_test, model.predict(X_test_selected)),\n",
    "      'F1': f1_score(y_test, model.predict(X_test_selected)),\n",
    "      'F2': fbeta_score(y_test, model.predict(X_test_selected), beta=2, average='binary')\n",
    "\n",
    "      }\n",
    "          \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name = []\n",
    "auc = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "f2 = []\n",
    "time_ = []\n",
    "\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    results = train_models(model, X_train_selected, X_test_selected, y_train, y_test)\n",
    "\n",
    "    name.append(type(model).__name__)\n",
    "    auc.append(results['AUC'])\n",
    "    accuracy.append(results['Accuracy'])\n",
    "    precision.append(results['Precision'])\n",
    "    recall.append(results['Recall'])\n",
    "    f1.append(results['F1'])\n",
    "    f2.append(results['F2'])\n",
    "    time_.append(time.time()-start)\n",
    "\n",
    "#Initialise data of lists\n",
    "models_rfe = pd.DataFrame(data=[name, auc, accuracy, precision, recall, f1, f2, time_]).T\n",
    "models_rfe.columns = ['Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1', 'F2','Time']\n",
    "models_rfe.sort_values('AUC', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models performance with features selection\n",
    "base_models_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ac07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Reminder before… features selection\n",
    "base_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Reminder before… features selection\n",
    "models_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_selected)[:,1])\n",
    "    cf_matrix_roc_auc(model, y_test, model.predict(X_test_selected), model.predict_proba(X_test_selected)[:,1], feature_importances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35f015",
   "metadata": {},
   "source": [
    "## Fonction de Cout\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b7d868c",
   "metadata": {},
   "source": [
    "La fonction coût sera déterminée par l'analyse des erreurs de prédiction\n",
    " On peut se fixer l'hypothèse d'un Beta = 3. Vérifions-le avec une étape de tests fonctionnels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a92fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tests fonctionels avec des listes contenant 4 int: tp, tn, fp, fn\n",
    "test_0 = [500, 300, 10, 30]\n",
    "test_1 = [500, 300, 30, 10]\n",
    "test_2 = [400, 300, 70, 50]\n",
    "test_3 = [400, 300, 50, 70]\n",
    "test_4 = [350, 250, 80, 120]\n",
    "test_5 = [350, 250, 180, 90]\n",
    "\n",
    "tests = [test_0, test_1, test_2, test_3, test_4, test_5]\n",
    "\n",
    "\n",
    "def my_score(predictions_success: list) -> int:\n",
    "    '''scoring fonction'''\n",
    "    tp, tn, fp, fn = predictions_success\n",
    "  \n",
    "    beta = 3\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp) \n",
    "    fscore = (1+beta)*(tp / ((1+3)*tp + beta*fn + fp))\n",
    "    \n",
    "    return 1-fscore\n",
    "\n",
    "for i, t in enumerate(tests):\n",
    "    print(\"############################\")\n",
    "    print(\"Test\", i, \":\", t)\n",
    "    print(\"Score :\", my_score(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred, beta=3) :\n",
    "    '''function penalize fp and fn…'''\n",
    "    tp, tn, fp, fn = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    fscore = (1+beta)*((tp / ((1+beta)*tp + beta*fn + fp)))\n",
    "\n",
    "    return 1-fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8749f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_false(model, y_true, X_true):\n",
    "    '''Cost function analyzes prediction errors False Pos. and False Neg.'''\n",
    "    cm = confusion_matrix(y_true, model.predict(X_true))\n",
    "    FP = cm[0][1]/np.sum(cm)\n",
    "    FN = cm[1][0]/np.sum(cm)\n",
    "  \n",
    "    print(\"False Pos: {0:.2%}\".format(FP))\n",
    "    print(\"False Neg: {0:.2%}\".format(FN))\n",
    "    return FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809d831",
   "metadata": {},
   "source": [
    "## Hyperparameters tunning - Hyperopt et AUC score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af18cc05",
   "metadata": {},
   "source": [
    "Choisir les hyperparamètres appropriés est nécessaire pour affiner et booster les performances d'un algorithme d’apprentissage automatique. La métrique utilisée dans le contexte de notre classification binaire sera l'AUC score.\n",
    "\n",
    "Grid Search ou Random Search étaient également une alternative possible, à la différence d'Hyperopt une \"méthode basique\" ne permet pas de traiter un large espace de paramètres, ici très largement privilégié.\n",
    "\n",
    "Avec Hyperopt, on peut facilement analyser notre modèle de Boosting tout en variant les hyperparamètres dans l'espace que nous allons définir ci-dessous. Hyperopt fonctionne avec les algorithmes de ML distribué, comme Apache Spark MLlib et Horovod, ainsi qu’avec les modèles ML mono-machine, comme scikit-learn et TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ba5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install networkx\n",
    "#!pip install hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "#Parameter space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 500, 1000, 500),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 10, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.60, 0.95),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.60, 0.95),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 20)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, eval_metric='custom_score'):\n",
    "    #objective function to be minimized. \n",
    "    #Hyperopt will seek to minimize the loss returned by this function.\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'reg_lambda': params['reg_lambda'],\n",
    "        'device':'gpu'\n",
    "        }\n",
    "      \n",
    "    model= LGBMClassifier(**params)\n",
    "    cv = StratifiedKFold(5)\n",
    "    if eval_metric == 'roc_auc': \n",
    "        score = cross_val_score(model, X_train_selected, y_train, scoring='roc_auc', cv=cv).mean()\n",
    "\n",
    "    elif eval_metric == 'custom_score': \n",
    "        y_pred = cross_val_predict(model, X_train_selected, y_train, method='predict', cv=cv)\n",
    "        #y_pred = cross_val_predict(model, X_train, y_train, method='predict', cv=cv)\n",
    "        score = custom_score(y_train, y_pred)\n",
    "  \n",
    "    loss = 1 - score    \n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best = fmin(fn=objective, space=space, max_evals=10, rstate=np.random.default_rng(1), algo=tpe.suggest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier( #Fit a new model based on the best parameters\n",
    "    n_estimators=int(best['n_estimators']), \n",
    "    colsample_bytree= best['colsample_bytree'],\n",
    "    learning_rate= best['learning_rate'],\n",
    "    max_depth= int(best['max_depth']),\n",
    "    subsample= best['subsample'],\n",
    "    reg_lambda= best['reg_lambda'],\n",
    "    device='gpu')\n",
    "\n",
    "lgbm.fit(X_train_selected, y_train)\n",
    "#lgbm.fit(X_train, y_train)\n",
    "pickle.dump(lgbm, open(\"LGBMClassifier.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, lgbm.predict_proba(X_test_selected)[:,1])\n",
    "#roc_auc = roc_auc_score(y_test, lgbm.predict_proba(X_test)[:,1])\n",
    "print('AUC : %0.6f' %roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e924767",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_roc_auc(lgbm, y_test, lgbm.predict(X_test_selected), lgbm.predict_proba(X_test_selected)[:,1], feature_importances=True)\n",
    "#cf_matrix_roc_auc(lgbm, y_test, lgbm.predict(X_test), lgbm.predict_proba(X_test)[:,1], feature_importances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP and FN\n",
    "cost_false(lgbm, y_test, X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e94b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check list features importance \n",
    "sorted_idx = np.argsort(lgbm.feature_importances_)[::-1]\n",
    "for index in sorted_idx:\n",
    "    print([X_data.columns[index], lgbm.feature_importances_[index]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a794f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, eval_metric='roc_auc'):\n",
    "  #objective function to be minimized. \n",
    "  #Hyperopt will seek to minimize the loss returned by this function.\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'reg_lambda': params['reg_lambda'],\n",
    "        'device':'gpu'}\n",
    "  \n",
    "    \n",
    "    model= LGBMClassifier(**params)\n",
    "    cv = StratifiedKFold(5)\n",
    "    if eval_metric == 'roc_auc': \n",
    "        score = cross_val_score(model, X_train_selected, y_train, scoring='roc_auc', cv=cv).mean()\n",
    "\n",
    "    elif eval_metric == 'custom_score': \n",
    "        y_pred = cross_val_predict(model, X_train_selected, y_train, method='predict', cv=cv)\n",
    "        score = custom_score(y_train, y_pred)\n",
    "  \n",
    "    loss = 1 - score    \n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best = fmin(fn=objective, space=space, max_evals=10, rstate=np.random.default_rng(1), algo=tpe.suggest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b970f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier( #Fit a new model based on the best parameters\n",
    "    n_estimators=int(best['n_estimators']), \n",
    "    colsample_bytree= best['colsample_bytree'],\n",
    "    learning_rate= best['learning_rate'],\n",
    "    max_depth= int(best['max_depth']),\n",
    "    subsample= best['subsample'],\n",
    "    reg_lambda= best['reg_lambda'],\n",
    "    device='gpu')\n",
    "\n",
    "lgbm.fit(X_train_selected, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f454745",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, lgbm.predict_proba(X_test_selected)[:,1])\n",
    "print('AUC : %0.6f' %roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_roc_auc(lgbm, y_test, lgbm.predict(X_test_selected), lgbm.predict_proba(X_test_selected)[:,1], feature_importances=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3940a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
